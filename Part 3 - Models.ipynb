{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in /usr/local/lib/python3.5/dist-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte  train-images-idx3-ubyte\r\n",
      "t10k-labels-idx1-ubyte  train-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "ls ../python-mnist/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('../python-mnist/data/') #bring mnist training set into this notebook\n",
    "train_x, train_y = mndata.load_training()\n",
    "test_x, test_y = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784, 60000, 10000, 784, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(train_x[0]), len(train_y), len(test_x), len(test_x[0]), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x[:10000],[10000, 784])\n",
    "train_y = np.array(train_y[:10000])\n",
    "test_x = np.reshape(test_x, [len(test_x), 784])\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784, 10000, 10000, 784, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(train_x[0]), len(train_y), len(test_x), len(test_x[0]), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with Naive(ish) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg = LogisticRegression(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "385.27641892433167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "lgrg.fit(train_x, train_y)\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.06989765167236328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "display(lgrg.score(test_x, test_y))\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259656429290771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94420000000000004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "74.41751194000244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "display(knn.score(test_x, test_y))\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: the two models below suffer greatly from the reduced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.965087413787842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(train_x, train_y)\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65300000000000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6891567707061768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "display(ada.score(test_x, test_y))\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.38808488845825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(train_x, train_y)\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "78.20779037475586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = time()\n",
    "display(svc.score(test_x, test_y))\n",
    "\n",
    "t2 = time()\n",
    "display(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridsearchCV Models Did Not Work Due to RAM Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = time()\n",
    "#\n",
    "#lgrg_pipeline = Pipeline([\n",
    "#    ('logreg', LogisticRegression())\n",
    "#])\n",
    "#lgrg_params = {\n",
    "#    'multi_class':['multinomial'],\n",
    "#    'logreg__solver':['newton-cg', 'liblinear', 'sag'],\n",
    "#    'logreg__C': [0.001, 0.1, 10, 1000],\n",
    "#}\n",
    "#pipe_gs = GridSearchCV(lgrg_pipeline, param_grid= lgrg_params, cv=3, n_jobs= -1)\n",
    "#pipe_gs.fit(train_x, train_y)\n",
    "#\n",
    "#t2 = time()\n",
    "#display(t2-t1)\n",
    "#\n",
    "#t1 = time()\n",
    "#\n",
    "#knn_pipeline = Pipeline([\n",
    "#    ('knn', KNeighborsClassifier())\n",
    "#])\n",
    "#knn_params = {\n",
    "#    'knn__n_neighbors':[3, 5, 15], \n",
    "#    'knn__leaf_size':[10, 30, 100],\n",
    "#    'knn__p':[1, 2], \n",
    "#}\n",
    "#pipe_gs = GridSearchCV(knn_pipeline, param_grid= knn_params, cv=5, n_jobs=-1)\n",
    "#pipe_gs.fit(train_x, train_y)\n",
    "#\n",
    "#t2 = time()\n",
    "#display(t2-t1)\n",
    "#\n",
    "#t1 = time()\n",
    "#\n",
    "#ada_pipeline = Pipeline([\n",
    "#    ('ada', AdaBoostClassifier())\n",
    "#])\n",
    "#ada_params = {\n",
    "#    'ada__n_estimators':[25, 50], \n",
    "#    'ada__learning_rate':[0.5, 1.0],\n",
    "#    'ada__random_state': [42],\n",
    "#}\n",
    "#pipe_gs = GridSearchCV(ada_pipeline, param_grid= ada_params, cv=3, n_jobs=-1)\n",
    "#pipe_gs.fit(train_x, train_y)\n",
    "#\n",
    "#t2 = time()\n",
    "#display(t2-t1)\n",
    "#\n",
    "#t1 = time()\n",
    "#\n",
    "#svc_pipeline = Pipeline([\n",
    "#    ('svc', SVC())\n",
    "#])\n",
    "#svc_params = {\n",
    "#    'svc__C': np.logspace(-3, 2, 6), \n",
    "#    'svc__kernel':['linear', 'rbf'],\n",
    "#    'svc__degree': [1, 2, 3],\n",
    "#}\n",
    "#pipe_gs = GridSearchCV(svc_pipeline, param_grid= svc_params, cv=3, n_jobs=-1)\n",
    "#pipe_gs.fit(train_x, train_y)\n",
    "#\n",
    "#t2 = time()\n",
    "#display(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
